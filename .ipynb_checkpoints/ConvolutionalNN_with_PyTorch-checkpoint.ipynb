{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks with PyTorch\n",
    "\n",
    "by Héctor Ramírez\n",
    "\n",
    "<hr>\n",
    "\n",
    "In this notebook, we construct two Convolutional Neural Networks (CNN) for image classification, using the <a href='https://pytorch.org'><b>PyTorch</b></a> library. Among the advantages of using PyTorch - instead of Keras or TensorFlow - we can mention:\n",
    "<ul>\n",
    "    <li> Easy to use. </li>\n",
    "    <li> Strong GPU support. </li>\n",
    "    <li> Strong object oriented programming (OOP) support, which is a natural choice for several companies as, <i>e.g.</i>, FaceBook.\n",
    "</ul>\n",
    "\n",
    "For these exercises, we will use the <a href='http://www.cs.toronto.edu/~kriz/cifar.html'><b>CIFAR-10</b></a> dataset which consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "The dataset is included in the <code>torchvision.datasets</code> library and thus can be downloaded locally. Here, we downlowad both the training and tests sets and construct the train and test loaders following the specified transformation in order to prepare the data for training.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "We can inspect the images thanks to an accompanion script taken from <a href='https://github.com/deep-diver/CIFAR10-img-classification-tensorflow/blob/master/CIFAR10_image_classification.ipynb'>this</a> repository. Choosing an arbitrary batch and sample, it provides the number of samples in the batch, the count number of values of each type in the batch, the range of values for the image and its label.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #2:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 984\n",
      "Label Counts of [1](AUTOMOBILE) : 1007\n",
      "Label Counts of [2](BIRD) : 1010\n",
      "Label Counts of [3](CAT) : 995\n",
      "Label Counts of [4](DEER) : 1010\n",
      "Label Counts of [5](DOG) : 988\n",
      "Label Counts of [6](FROG) : 1008\n",
      "Label Counts of [7](HORSE) : 1026\n",
      "Label Counts of [8](SHIP) : 987\n",
      "Label Counts of [9](TRUCK) : 985\n",
      "\n",
      "Example of Image 6145:\n",
      "Image - Min Value: 0 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 7 Name: horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Images import display_stats\n",
    "import numpy as np\n",
    "\n",
    "cifar10_dataset_folder_path = './data/cifar-10-batches-py'\n",
    "batch_id = np.random.randint(1, 6)\n",
    "sample_id = np.random.randint(10000)\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Image classification\n",
    "\n",
    "We will construct two CNNs where we will use MaxPooling as feature selector and ReLU as activation function. First we will construct a simple and fast network with two convolutional and one linear layers; and then, a more complex network, using the <code>.Sequential()</code> module, with three convolutional layers, three fully-connected linear layers, batch normalization and L2 regularization.\n",
    "<br><br>\n",
    "The recipe for the CNN would be:\n",
    "<ol>\n",
    "    <li>Declare convolutional (and fully-connected linear) layers with arbitrarily increasing output channels.</li>\n",
    "    <li>Do forward pass.</li>\n",
    "    <li>Calculate the loss function.</li>\n",
    "    <li>Calculate the gradients using backward propagation.</li>\n",
    "    <li>Update the parameters based on the gradients (<code>optimizer.step()</code> method).</li>\n",
    "</ol>\n",
    "\n",
    "### Network 1:\n",
    "The first CNN consists of: \n",
    "<ul>\n",
    "    <li>Two convolutional layers of size 3 with padding.</li>\n",
    "    <li>ReLU activation and MaxPooling after each convolutional layer.</li>\n",
    "    <li>Finally, a fully-connected Linear layer.</li>\n",
    "</ul>\n",
    "Given that we are working with the PyTorch library, we construct the network in a <code>class</code> module where we declare the convolutional and linear layer and then we define the forward pass method.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network 1\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(64 * 8 * 8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Squeeze the three spatial dimensions in one\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "We then instantiate the network and define the Loss function, <code>.CrossEntropyLoss()</code> in this case; the optimizer, <code>.Adam()</code>, with a specific learning rate.\n",
    "<br<br>\n",
    "Then we train the network using the train loader.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Once it finished training, we test it using the test loader and print the accuracy of this network.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 67 %\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Network 2:\n",
    "The second CNN consists of: \n",
    "<ul>\n",
    "    <li>Three convolutional layers of size 3 with padding.</li>\n",
    "    <li>ReLU activation, MaxPooling and batch normalization after each convolutional layer.</li>\n",
    "    <li>Three fully-connected Linear layers with ReLU activation.</li>\n",
    "</ul>\n",
    "To make the architecture simpler, we make use of the <code>.Sequential()</code> module. We define the forward pass method as usual.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network 2:\n",
    "class Netb(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Netb, self).__init__()\n",
    "\n",
    "        # Implement the sequential module for feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(num_features=32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(num_features=64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(num_features=128))\n",
    "\n",
    "        # Implement the fully connected layer for classification\n",
    "        self.fc = nn.Linear(in_features=128 * 4 * 4, out_features=num_classes)\n",
    "        self.classifier = nn.Sequential(nn.Linear(128 * 4 * 4, 1024), nn.ReLU(inplace=True),\n",
    "                                        nn.Linear(1024, 2048), nn.ReLU(inplace=True),\n",
    "                                        nn.Linear(2048, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "We then again instantiate the new network with now an optimizer with L2 regularization, specified by the <i>weight_decay</i> parameter. Then, we train it.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Netb()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4, weight_decay=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Once it finished training, we test it using the test loader and print the accuracy of this network.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 71 %\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "For state-of-the-art algorithms with an accuracy well above the ones obtained here, please refer to this <a href='http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130'>blog</a>.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
